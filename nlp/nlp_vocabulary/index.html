<!DOCTYPE html>
<html>
<head>
    <title>자연어처리/머신러닝 용어집</title>
    <meta charset="utf-8">
    <meta http-equiv="content-type" content="text/html; charset=utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1">
    
    
    

        <meta property="og:title" content="자연어처리/머신러닝 용어집" />
    
    <meta property="og:description" content="" />
    <meta property="og:type" content="website" />
    <meta property="og:locale" content="en" />
    <meta property="og:url" content="https://happygrammer.github.io/nlp/nlp_vocabulary/" />
    
    <meta property="og:image" content="https://happygrammer.github.io/thumnail.jpg" />
    <meta name="twitter:image" content="https://happygrammer.github.io/thumnail.jpg" />

    <script src="https://happygrammer.github.io/js/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
</script>
<script type="text/x-mathjax-config">
  MathJax.Hub.Config({tex2jax: {inlineMath: [['$','$'], ['\\(','\\)']]}});
</script>

    <link rel="shortcut icon" href="/favicon.ico">
    <link href="https://happygrammer.github.io/webfonts/ptserif/main.css" rel='stylesheet' type='text/css'>
    <link href="https://happygrammer.github.io/webfonts/source-code-pro/main.css" rel="stylesheet" type="text/css">
    <link rel="stylesheet" href="https://happygrammer.github.io/css/style.css">
    
    <meta name="generator" content="Hugo 0.62.0" />
</head>


<body>
<div id="container">
	<div id="fb-root"></div>
	
    <header id="header">
    <div id="header-outer" class="outer">
        <div id="header-inner" class="inner">
            <a id="main-nav-toggle" class="nav-icon" href="javascript:;"></a>
            <a id="logo" class="logo-text" href="https://happygrammer.github.io/">해피그</a>
            <nav id="main-nav">
                
                <a class="main-nav-link" href="/about/">About</a>
                
                <a class="main-nav-link" href="/ai">AI</a>
                
                <a class="main-nav-link" href="/dev">Dev</a>
                
                <a class="main-nav-link" href="/insights">Insights</a>
                
                <a class="main-nav-link" href="/mlops">MLOps</a>
                
                <a class="main-nav-link" href="/nlp">NLP</a>
                
                <a class="main-nav-link" href="/rust">Rust</a>
                
		</nav>
            <nav id="sub-nav">
		<div id="search-form-wrap"></div>
            </nav>
        </div>
    </div>
</header>

    <section id="main" class="outer">
        <article class="article article-type-post" itemscope itemprop="blogPost">
    <div class="article-inner">
        
        <header class="article-header">
            
            <div><a href="/nlp/" class="archive-article-date">&lt; Nlps</a></div>
            
            <h1 class="article-title" itemprop="name">자연어처리/머신러닝 용어집</h1>
        </header>
        
        <div class="article-meta">
            <a href="/nlp/nlp_vocabulary/" class="article-date">
                <time datetime='2020-04-07T00:15:52.000&#43;03:00' itemprop="datePublished">2020-04-07</time>
            </a>
            
            
            
        </div>
        <div class="article-entry" itemprop="articleBody">
            <p>본 문서는  자연어처리/머신러닝 용어 목록을 소개합니다.</p>
<ul>
<li>
<p>Auto ML(Automated machine learning)</p>
<ul>
<li>엔지니어의 도움 없이도 머신 러닝 모델을 생성할 수 있는 머신러닝 솔루션</li>
<li>&ldquo;Data 처리, Feature 엔지니어링, Feature 추출, Feature 선택&quot;의 자동화 지원</li>
<li>관련 솔루션
<ul>
<li><a href="https://cloud.google.com/automl/?hl=ko">Google Cloud Platform - Cloud AutoML</a></li>
<li><a href="https://cloud.google.com/natural-language/automl/docs/features?hl=ko">Google Cloud Platform - AutoML NLP</a></li>
<li><a href="https://azure.microsoft.com/ko-kr/services/machine-learning/">Azure - Azure Machine Learning</a></li>
<li><a href="https://aws.amazon.com/ko/sagemaker/?nc2=h_ql_prod_ml_sm">AWS - Amazon SageMaker</a></li>
</ul>
</li>
</ul>
</li>
<li>
<p>Auto Regressive</p>
<ul>
<li>AR(순차적인 데이터 처리)</li>
<li>이러한 관점에서 ELmo, GPT를 AR 계열로 볼 수 있음</li>
</ul>
</li>
<li>
<p>BERT</p>
<ul>
<li>양방향 언어 모델</li>
<li>구글 브레인이 개발한 트랜스 포머 기반의 모델. 페이스북은 RoBERTa라는 새로운 알고리즘을 개발했다.</li>
</ul>
</li>
<li>
<p>Bootstrapping</p>
<ul>
<li>부스팅이라고도 불림, 샘플 데이터에서 랜덤 샘플링해 학습셋을 늘리는 방법으로, 정규 분포 성질을 가정함</li>
<li>크기가 동일한 n개의 샘플셋으로 구성함</li>
</ul>
</li>
<li>
<p>CTRL</p>
<ul>
<li>GPT-2보다 약간 더 큰 알고리즘으로, 글 스타일을 제어 가능</li>
</ul>
</li>
<li>
<p>ELMo(Embeddings from Language Model)</p>
<ul>
<li>2018년에 제안된 모델, 사전 훈련 언어 모델을 이용</li>
<li>문맥을 고려해 임베딩(Contextualized Word Embedding)
<ul>
<li>순방향, 역방향 RNN의 언어 모두를 고려한 biLM(Bidirectional Language Model)을 이용함</li>
</ul>
</li>
</ul>
</li>
<li>
<p>Fine tuning</p>
<ul>
<li>프리트레인으로 공통 도메인 학습 후 파인 튜닝을 통해 다운스트림 태스크 맞게 데이터 추가 하여 파라미터를 미세 조정해 업데이트 하는 방법</li>
<li>출력 층에 새로운 레이어를 추가, SGD(<strong>Stochastic gradient descent</strong>)를 수행함</li>
</ul>
</li>
<li>
<p><a href="https://github.com/openai/gpt-2">GPT-2</a></p>
<ul>
<li>대규모 언어 모델(large-scale langugage model), 단방향 언어 모델, 자연어 생성분야에 주목 받는 모델</li>
<li>오픈AI는 800만개의 웹 페이지에서 스랩된 15억개의 매개변수를 새로운 알고리즘으로 학습(GPT보다 Parameter와 데이터양이 10배 많아짐). 이 알고리즘을 이용해,  몇 문장에서 대부분 일관성 있는 몇 단락의 산문을 작성할 수 있게 되었다.</li>
<li>파인튜닝 없이 <code>Language modeling benchmark</code>에서 SOTA(State Of The Art) 달성</li>
</ul>
</li>
<li>
<p>Neural Network</p>
<ul>
<li>ANN(Artificial Neural Network) : 사람의 뇌에서 영감을 얻은 알고리즘으로 이미지 인식, 신호 인식 및 데이터 마이닝, 기계번역 등에서 활용 할 수 있는 모델</li>
<li>CNN : CNN은 데이터의 특징을 추출하여 특징들의 패턴을 파악하는 구조입니다. 이 CNN 알고리즘은 Convolution과정과 Pooling과정을 통해 진행</li>
<li>RNN : RNN 알고리즘은 반복적이고 순차적인 데이터(Sequential data)학습에 특화된 인공신경망의 한 종류로써 내부의 순환구조가 들어있다는 특징이 있음</li>
<li>DNN : ANN기법의 여러문제가 해결되면서 모델 내 은닉층을 많이 늘려서 학습의 결과를 향상시키는 방법이 등장하였고 이를 DNN(Deep Neural Network)라고 합니다. 딥러닝이라 부르며, DNN은 은닉층을 2개이상 지닌 학습 방법을 뜻함</li>
</ul>
</li>
<li>
<p>Outlier</p>
<ul>
<li>전체 데이터 패턴에서 비정상적으로 벗어난 값</li>
</ul>
</li>
<li>
<p>Permutation Language Model</p>
</li>
<li>
<p>Random Forest</p>
</li>
<li>
<ul>
<li><code>배깅</code>의 대표 알고리즘으로, 다수의 결정 트리로 부터 보팅 데이터 예측을 수행</li>
</ul>
</li>
<li>
<p>Seq2Seq</p>
<ul>
<li>하나의 도메인(한국어 문장)에서 또 다른 도메인(영어 문장)의 변환 학습 모델</li>
<li>언어 번역, 텍스트 요약, conversational model 등에 활용 가능</li>
</ul>
</li>
<li>
<p>SGD(<strong>Stochastic gradient descent</strong>)</p>
<ul>
<li>gradient descent로 이동시 마다 전체 데이터 중 일부 데이터를 사용해 사용함으로서 local optima 방지</li>
</ul>
</li>
<li>
<p>Transformer Network</p>
<ul>
<li>NIPS에 공개된 구글의 아키텍처로 GPT, BERT 등에서 사용됨</li>
<li>트랜스포머 블록 상단에 피드 포워드 네트워크와 하단의 멀티헤드 어텐션으로 구성됨
<ul>
<li>멀티헤드 어텐션은 Scaled Dot-Product Attention(문장내의 단어 쌍의 의미 관계 파악)을 N번 수행</li>
<li>피드 포워드 네트워크는 입력을 받아, 가중치를 적용하여 출력으로 내보내는 네트워크</li>
</ul>
</li>
</ul>
</li>
<li>
<p>Vanishing Gradient</p>
<ul>
<li>Vanishing Gradient Problem(기울기값이 사라지는 문제)는 인공신경망을 기울기값을 이용한 method(backpropagation)에서 발생하는 문제다.(sigmoid가 원인이 될 수 있음)
<ul>
<li>ReLu : linear함수인 sigmoid를 개선한 함수</li>
</ul>
</li>
</ul>
</li>
<li>
<p>Voting</p>
<ul>
<li>소프트보팅(soft voting) : k개의 분류기중 가장 큰 확률 값인 레이블을 선택하는 앙상블 방법</li>
<li>하드보팅(hard voting)  : k개의 분류기중 가장 많이 출력된 레이블을 선택하는 앙상블 방법</li>
</ul>
</li>
<li>
<p>XLNET</p>
<ul>
<li>XLNet은 구글(Yang et al., 2019)에서 발표한 아키텍처로 일부 데이터에 대해 BERT를 앞서는 성능을 보임</li>
<li>트랜스포머 네트워크(Vaswani et al., 2017)를 개선한 Transformer XL(eXtra-Long)의 모델로, 기존 Transformer에 비해 좀더 넓은 Context를 볼 수 있게 됨</li>
<li>RNN(문장 레벨의 Recurrency를 고려함)</li>
</ul>
</li>
</ul>

	    
	    <div class="fb-comments" data-href="https://happygrammer.github.io/nlp/nlp_vocabulary/" width="100%" data-width="" data-numposts="3"></div>
	</div>

        
        
        <div class="article-toc" >
            <nav id="TableOfContents"></nav>
        </div>
        
        
	


        
    </div>
    <nav id="article-nav">
    
    <a href="/nlp/hangeul/ambiguitymd/" id="article-nav-newer" class="article-nav-link-wrap">
        <div class="article-nav-title"><span>&lt;</span>&nbsp;
            중의성의 종류와 중의성 해소
        </div>
    </a>
    
    
    <a href="/insights/statistics/" id="article-nav-older" class="article-nav-link-wrap">
        <div class="article-nav-title">한국의 경제 지표&nbsp;<span>&gt;</span></div>
    </a>
    
</nav>

</article>

        
    </section>
    <footer id="footer">
    

    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.9.0/styles/tomorrow-night.min.css" integrity="sha256-2wL88NKUqvJi/ExflDzkzUumjUM73mcK2gBvBBeLvTk=" crossorigin="anonymous" />
    <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.9.0/highlight.min.js" integrity="sha256-KbfTjB0WZ8vvXngdpJGY3Yp3xKk+tttbqClO11anCIU=" crossorigin="anonymous"></script>
    <script>hljs.initHighlightingOnLoad();</script>

    
    <script>
        document.getElementById('main-nav-toggle').addEventListener('click', function () {
            var header = document.getElementById('header');
            if (header.classList.contains('mobile-on')) {
                header.classList.remove('mobile-on');
            } else {
                header.classList.add('mobile-on');
            }
        });
    </script>
</footer>

</div>
</body>
</html>
